<img src="https://i.imgur.com/ucvNYzR.png"></img>
<table>
  <tr>
    <td valign="top" width="50%">
      <h2>üë©‚Äçüíª <a href="https://github.com/midiblocks/midiblocks-web">Midiblocks</a></h2>
      <i>A handsfree platform and coding environment for using websites, browsers, desktops, robots...pretty much anything handsfree! Beta 11/8</i><br><br>
      <img src="https://media4.giphy.com/media/YATR9GZSSHKeNw3fht/giphy.gif">
    </td>
    <td valign="top" width="50%">
      <h2>üëã <a href="https://github.com/midiblocks/handsfree">Handsfree.js</a></h2>
      <i>Handsfree.js exposes several computer vision models around a single API for interacting with websites handsfree via <a href="https://github.com/jeeliz/jeelizWeboji">Weboji</a>, <a href="https://github.com/tensorflow/tfjs-models/tree/master/posenet">PoseNet</a>, <a href="https://github.com/tensorflow/tfjs-models/tree/master/body-pix">BodyPix</a>, and soon others more!</i><br><br>
      <img src="https://media0.giphy.com/media/Iv2aSMS0QTy2P5JNCX/giphy.gif">
    </td>
  </tr>
</table>

---

## Milestones

### General
- [ ] Document [Handsfree.js](https://github.com/midiblocks/handsfree) (I haven't updated since earlier Spring üòÖ)
- [ ] Move [midiblocks-web](https://github.com/midiblocks/midiblocks-web) into beta, meaning people can map face gestures to desktop mouse/keyboard
- [ ] Record myself playing the top 25 NES games handsfree through [Midiblocks on YouTube](https://www.youtube.com/channel/UCDzb8yXGOm6ZYd0Jf_FYKWA)

### Handsfree.js
- [ ] Expose [WebGazer](https://github.com/brownhci/WebGazer)
- [ ] Expose [Handtracking](https://github.com/tensorflow/tfjs-models/tree/master/handpose)
- [ ] Expose Voice
- [ ] Expose Mind Control

### Midiblocks
- [ ] First face gesture based blocks
- [ ] Mappings for basic mouse controls
- [ ] Mappings for basic keyboard controls
- [ ] Accessible by screen readers

---

## More
- [Twitter @Midiblocks](https://twitter.com/midiblocks)
- [YouTube](https://www.youtube.com/channel/UCDzb8yXGOm6ZYd0Jf_FYKWA)